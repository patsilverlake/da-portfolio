{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Asset Portfolio Optimization & Backtesting Analysis\n",
    "\n",
    "## Objective\n",
    "Demonstrate how strategic alt exposure (even large-cap alts) can potentially generate superior risk-adjusted returns compared to a pure Bitcoin buy-and-hold strategy.\n",
    "\n",
    "## Portfolios Under Analysis\n",
    "1. **Benchmark**: 100% Bitcoin (BTC)\n",
    "2. **3-Asset Portfolio**: BTC + ETH + SOL (optimized weights)\n",
    "3. **5-Asset Portfolio**: BTC + ETH + SOL + BNB + XRP (optimized weights)\n",
    "\n",
    "## Definition of \"Best\"\n",
    "\n",
    "We define \"best\" using multiple criteria to provide a holistic view:\n",
    "\n",
    "### Primary Metric: Sharpe Ratio (Risk-Adjusted Returns)\n",
    "- **Why**: Investors care about returns relative to risk taken. A 200% return with 150% volatility is worse than 100% return with 40% volatility from a risk-adjusted perspective.\n",
    "- **Formula**: (Portfolio Return - Risk-Free Rate) / Portfolio Volatility\n",
    "\n",
    "### Secondary Metrics:\n",
    "- **CAGR**: Compound Annual Growth Rate - raw performance\n",
    "- **Max Drawdown**: Worst peak-to-trough decline - downside risk\n",
    "- **Sortino Ratio**: Like Sharpe but only penalizes downside volatility\n",
    "- **Calmar Ratio**: CAGR / Max Drawdown - return per unit of drawdown risk\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install yfinance pandas numpy matplotlib seaborn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import minimize\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Constants\n",
    "RISK_FREE_RATE = 0.03  # 3% annual risk-free rate\n",
    "TRADING_DAYS = 365     # Crypto trades 365 days/year\n",
    "INITIAL_INVESTMENT = 10000\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition\n",
    "\n",
    "Fetch historical price data from Yahoo Finance. We'll use the longest common history where all assets have data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2020-04-01 to 2026-01-20...\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ticker \u001b[38;5;129;01min\u001b[39;00m ASSETS.items():\n\u001b[32m     19\u001b[39m     data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     prices[name] = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAdj Close\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m days of data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Drop any rows with missing data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4101\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4100\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4101\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4102\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4159\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   4158\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4159\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   4161\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3040\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3041\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3043\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3391\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3388\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3390\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3391\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3394\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3395\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3396\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2980\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2979\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "# Define assets\n",
    "ASSETS = {\n",
    "    'BTC': 'BTC-USD',\n",
    "    'ETH': 'ETH-USD', \n",
    "    'SOL': 'SOL-USD',\n",
    "    'BNB': 'BNB-USD',\n",
    "    'XRP': 'XRP-USD'\n",
    "}\n",
    "\n",
    "# Fetch data - SOL launched in March 2020, so we start from April 2020\n",
    "START_DATE = '2020-04-01'\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Fetching data from {START_DATE} to {END_DATE}...\")\n",
    "\n",
    "# Download all assets\n",
    "prices = pd.DataFrame()\n",
    "for name, ticker in ASSETS.items():\n",
    "    data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
    "    prices[name] = data['Adj Close']\n",
    "    print(f\"  {name}: {len(data)} days of data\")\n",
    "\n",
    "# Drop any rows with missing data\n",
    "prices = prices.dropna()\n",
    "print(f\"\\nTotal aligned data points: {len(prices)} days\")\n",
    "print(f\"Date range: {prices.index[0].strftime('%Y-%m-%d')} to {prices.index[-1].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Daily Returns Summary Statistics:\")\n",
    "print(returns.describe().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Portfolio Metrics Functions\n",
    "\n",
    "Define functions to calculate all key portfolio metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_portfolio_returns(weights, returns_df):\n",
    "    \"\"\"\n",
    "    Calculate portfolio daily returns given weights and asset returns.\n",
    "    \"\"\"\n",
    "    return (returns_df * weights).sum(axis=1)\n",
    "\n",
    "\n",
    "def calculate_portfolio_value(weights, prices_df, initial_investment=INITIAL_INVESTMENT):\n",
    "    \"\"\"\n",
    "    Calculate portfolio value over time with buy-and-hold (no rebalancing).\n",
    "    \"\"\"\n",
    "    # Initial allocation\n",
    "    initial_prices = prices_df.iloc[0]\n",
    "    units = (initial_investment * np.array(weights)) / initial_prices\n",
    "    \n",
    "    # Portfolio value over time\n",
    "    portfolio_values = (prices_df * units).sum(axis=1)\n",
    "    return portfolio_values\n",
    "\n",
    "\n",
    "def calculate_metrics(portfolio_values, daily_returns=None):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive portfolio metrics.\n",
    "    \"\"\"\n",
    "    if daily_returns is None:\n",
    "        daily_returns = portfolio_values.pct_change().dropna()\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_return = (portfolio_values.iloc[-1] / portfolio_values.iloc[0]) - 1\n",
    "    \n",
    "    # Time period in years\n",
    "    years = (portfolio_values.index[-1] - portfolio_values.index[0]).days / 365\n",
    "    \n",
    "    # CAGR\n",
    "    cagr = (portfolio_values.iloc[-1] / portfolio_values.iloc[0]) ** (1/years) - 1\n",
    "    \n",
    "    # Volatility (annualized)\n",
    "    volatility = daily_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe = (cagr - RISK_FREE_RATE) / volatility if volatility != 0 else 0\n",
    "    \n",
    "    # Max Drawdown\n",
    "    rolling_max = portfolio_values.expanding().max()\n",
    "    drawdowns = (portfolio_values - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdowns.min()\n",
    "    \n",
    "    # Sortino Ratio (only downside volatility)\n",
    "    downside_returns = daily_returns[daily_returns < 0]\n",
    "    downside_std = downside_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "    sortino = (cagr - RISK_FREE_RATE) / downside_std if downside_std != 0 else 0\n",
    "    \n",
    "    # Calmar Ratio\n",
    "    calmar = cagr / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "    \n",
    "    # Best/Worst Days\n",
    "    best_day = daily_returns.max()\n",
    "    worst_day = daily_returns.min()\n",
    "    \n",
    "    # Win Rate\n",
    "    win_rate = (daily_returns > 0).sum() / len(daily_returns)\n",
    "    \n",
    "    return {\n",
    "        'total_return': total_return,\n",
    "        'cagr': cagr,\n",
    "        'volatility': volatility,\n",
    "        'sharpe': sharpe,\n",
    "        'sortino': sortino,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'calmar': calmar,\n",
    "        'best_day': best_day,\n",
    "        'worst_day': worst_day,\n",
    "        'win_rate': win_rate,\n",
    "        'final_value': portfolio_values.iloc[-1]\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Metric functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Portfolio Optimization\n",
    "\n",
    "Find optimal weights for 3-asset and 5-asset portfolios using grid search to maximize Sharpe Ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_portfolio_grid(assets_list, returns_df, prices_df, step=5):\n",
    "    \"\"\"\n",
    "    Grid search optimization to find weights that maximize Sharpe ratio.\n",
    "    Step size in percentage points (e.g., 5 = 0%, 5%, 10%, ..., 100%)\n",
    "    \"\"\"\n",
    "    n_assets = len(assets_list)\n",
    "    asset_returns = returns_df[assets_list]\n",
    "    asset_prices = prices_df[assets_list]\n",
    "    \n",
    "    best_sharpe = -np.inf\n",
    "    best_weights = None\n",
    "    best_metrics = None\n",
    "    \n",
    "    # Generate all weight combinations that sum to 100\n",
    "    weight_range = range(0, 101, step)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if n_assets == 3:\n",
    "        for w1 in weight_range:\n",
    "            for w2 in weight_range:\n",
    "                w3 = 100 - w1 - w2\n",
    "                if 0 <= w3 <= 100:\n",
    "                    weights = np.array([w1, w2, w3]) / 100\n",
    "                    pv = calculate_portfolio_value(weights, asset_prices)\n",
    "                    metrics = calculate_metrics(pv)\n",
    "                    results.append({\n",
    "                        'weights': weights,\n",
    "                        **{f'w_{a}': w for a, w in zip(assets_list, weights)},\n",
    "                        **metrics\n",
    "                    })\n",
    "                    if metrics['sharpe'] > best_sharpe:\n",
    "                        best_sharpe = metrics['sharpe']\n",
    "                        best_weights = weights\n",
    "                        best_metrics = metrics\n",
    "                        \n",
    "    elif n_assets == 5:\n",
    "        for w1 in weight_range:\n",
    "            for w2 in weight_range:\n",
    "                for w3 in weight_range:\n",
    "                    for w4 in weight_range:\n",
    "                        w5 = 100 - w1 - w2 - w3 - w4\n",
    "                        if 0 <= w5 <= 100:\n",
    "                            weights = np.array([w1, w2, w3, w4, w5]) / 100\n",
    "                            pv = calculate_portfolio_value(weights, asset_prices)\n",
    "                            metrics = calculate_metrics(pv)\n",
    "                            results.append({\n",
    "                                'weights': weights,\n",
    "                                **{f'w_{a}': w for a, w in zip(assets_list, weights)},\n",
    "                                **metrics\n",
    "                            })\n",
    "                            if metrics['sharpe'] > best_sharpe:\n",
    "                                best_sharpe = metrics['sharpe']\n",
    "                                best_weights = weights\n",
    "                                best_metrics = metrics\n",
    "    \n",
    "    return best_weights, best_metrics, pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"Optimization function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize 3-Asset Portfolio (BTC, ETH, SOL)\n",
    "print(\"Optimizing 3-Asset Portfolio (BTC, ETH, SOL)...\")\n",
    "assets_3 = ['BTC', 'ETH', 'SOL']\n",
    "optimal_weights_3, optimal_metrics_3, results_3 = optimize_portfolio_grid(assets_3, returns, prices, step=5)\n",
    "\n",
    "print(f\"\\nOptimal 3-Asset Weights:\")\n",
    "for asset, weight in zip(assets_3, optimal_weights_3):\n",
    "    print(f\"  {asset}: {weight*100:.1f}%\")\n",
    "print(f\"Sharpe Ratio: {optimal_metrics_3['sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize 5-Asset Portfolio (BTC, ETH, SOL, BNB, XRP)\n",
    "print(\"Optimizing 5-Asset Portfolio (BTC, ETH, SOL, BNB, XRP)...\")\n",
    "print(\"This may take a moment due to larger search space...\")\n",
    "assets_5 = ['BTC', 'ETH', 'SOL', 'BNB', 'XRP']\n",
    "optimal_weights_5, optimal_metrics_5, results_5 = optimize_portfolio_grid(assets_5, returns, prices, step=10)\n",
    "\n",
    "print(f\"\\nOptimal 5-Asset Weights:\")\n",
    "for asset, weight in zip(assets_5, optimal_weights_5):\n",
    "    print(f\"  {asset}: {weight*100:.1f}%\")\n",
    "print(f\"Sharpe Ratio: {optimal_metrics_5['sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bitcoin-only benchmark\n",
    "print(\"Calculating Bitcoin benchmark...\")\n",
    "btc_values = calculate_portfolio_value([1.0], prices[['BTC']])\n",
    "btc_metrics = calculate_metrics(btc_values)\n",
    "\n",
    "print(f\"\\nBitcoin (100% BTC) Performance:\")\n",
    "print(f\"  Total Return: {btc_metrics['total_return']*100:.1f}%\")\n",
    "print(f\"  Sharpe Ratio: {btc_metrics['sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Portfolio Comparison\n",
    "\n",
    "Compare all three portfolios across key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio values for visualization\n",
    "portfolio_3_values = calculate_portfolio_value(optimal_weights_3, prices[assets_3])\n",
    "portfolio_5_values = calculate_portfolio_value(optimal_weights_5, prices[assets_5])\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        'Total Return',\n",
    "        'CAGR',\n",
    "        'Volatility (Annualized)',\n",
    "        'Sharpe Ratio',\n",
    "        'Sortino Ratio', \n",
    "        'Max Drawdown',\n",
    "        'Calmar Ratio',\n",
    "        'Best Day',\n",
    "        'Worst Day',\n",
    "        'Win Rate',\n",
    "        f'Final Value (${INITIAL_INVESTMENT:,} invested)'\n",
    "    ],\n",
    "    '100% BTC': [\n",
    "        f\"{btc_metrics['total_return']*100:.1f}%\",\n",
    "        f\"{btc_metrics['cagr']*100:.1f}%\",\n",
    "        f\"{btc_metrics['volatility']*100:.1f}%\",\n",
    "        f\"{btc_metrics['sharpe']:.3f}\",\n",
    "        f\"{btc_metrics['sortino']:.3f}\",\n",
    "        f\"{btc_metrics['max_drawdown']*100:.1f}%\",\n",
    "        f\"{btc_metrics['calmar']:.3f}\",\n",
    "        f\"{btc_metrics['best_day']*100:.1f}%\",\n",
    "        f\"{btc_metrics['worst_day']*100:.1f}%\",\n",
    "        f\"{btc_metrics['win_rate']*100:.1f}%\",\n",
    "        f\"${btc_metrics['final_value']:,.0f}\"\n",
    "    ],\n",
    "    '3-Asset Optimal': [\n",
    "        f\"{optimal_metrics_3['total_return']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_3['cagr']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_3['volatility']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_3['sharpe']:.3f}\",\n",
    "        f\"{optimal_metrics_3['sortino']:.3f}\",\n",
    "        f\"{optimal_metrics_3['max_drawdown']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_3['calmar']:.3f}\",\n",
    "        f\"{optimal_metrics_3['best_day']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_3['worst_day']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_3['win_rate']*100:.1f}%\",\n",
    "        f\"${optimal_metrics_3['final_value']:,.0f}\"\n",
    "    ],\n",
    "    '5-Asset Optimal': [\n",
    "        f\"{optimal_metrics_5['total_return']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_5['cagr']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_5['volatility']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_5['sharpe']:.3f}\",\n",
    "        f\"{optimal_metrics_5['sortino']:.3f}\",\n",
    "        f\"{optimal_metrics_5['max_drawdown']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_5['calmar']:.3f}\",\n",
    "        f\"{optimal_metrics_5['best_day']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_5['worst_day']*100:.1f}%\",\n",
    "        f\"{optimal_metrics_5['win_rate']*100:.1f}%\",\n",
    "        f\"${optimal_metrics_5['final_value']:,.0f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PORTFOLIO COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display optimal allocations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMAL PORTFOLIO ALLOCATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n3-Asset Portfolio (BTC/ETH/SOL):\")\n",
    "for asset, weight in zip(assets_3, optimal_weights_3):\n",
    "    print(f\"  {asset}: {weight*100:.0f}%\")\n",
    "\n",
    "print(\"\\n5-Asset Portfolio (BTC/ETH/SOL/BNB/XRP):\")\n",
    "for asset, weight in zip(assets_5, optimal_weights_5):\n",
    "    print(f\"  {asset}: {weight*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Portfolio Growth Comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax.plot(btc_values.index, btc_values, label='100% BTC', linewidth=2, color='#F7931A')\n",
    "ax.plot(portfolio_3_values.index, portfolio_3_values, label=f'3-Asset Optimal', linewidth=2, color='#627EEA')\n",
    "ax.plot(portfolio_5_values.index, portfolio_5_values, label=f'5-Asset Optimal', linewidth=2, color='#14F195')\n",
    "\n",
    "ax.set_title('Portfolio Growth Comparison (Buy & Hold, No Rebalancing)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "ax.legend(loc='upper left', fontsize=11)\n",
    "ax.set_yscale('log')  # Log scale to better visualize exponential growth\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations for final values\n",
    "for pv, name, color in [(btc_values, 'BTC', '#F7931A'), \n",
    "                         (portfolio_3_values, '3-Asset', '#627EEA'),\n",
    "                         (portfolio_5_values, '5-Asset', '#14F195')]:\n",
    "    final_val = pv.iloc[-1]\n",
    "    ax.annotate(f'${final_val:,.0f}', xy=(pv.index[-1], final_val),\n",
    "                xytext=(10, 0), textcoords='offset points', fontsize=10, color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Drawdown Comparison\n",
    "def calculate_drawdown_series(portfolio_values):\n",
    "    rolling_max = portfolio_values.expanding().max()\n",
    "    drawdowns = (portfolio_values - rolling_max) / rolling_max\n",
    "    return drawdowns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "dd_btc = calculate_drawdown_series(btc_values)\n",
    "dd_3 = calculate_drawdown_series(portfolio_3_values)\n",
    "dd_5 = calculate_drawdown_series(portfolio_5_values)\n",
    "\n",
    "ax.fill_between(dd_btc.index, dd_btc * 100, 0, alpha=0.3, label='100% BTC', color='#F7931A')\n",
    "ax.fill_between(dd_3.index, dd_3 * 100, 0, alpha=0.3, label='3-Asset', color='#627EEA')\n",
    "ax.fill_between(dd_5.index, dd_5 * 100, 0, alpha=0.3, label='5-Asset', color='#14F195')\n",
    "\n",
    "ax.set_title('Drawdown Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Drawdown (%)', fontsize=12)\n",
    "ax.legend(loc='lower left', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Risk-Return Scatter Plot (Efficient Frontier Visualization)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot all 3-asset combinations\n",
    "ax.scatter(results_3['volatility'] * 100, results_3['cagr'] * 100, \n",
    "           c=results_3['sharpe'], cmap='RdYlGn', alpha=0.5, s=30, label='3-Asset Combinations')\n",
    "\n",
    "# Highlight key portfolios\n",
    "portfolios = [\n",
    "    (btc_metrics['volatility']*100, btc_metrics['cagr']*100, '100% BTC', '#F7931A', 200),\n",
    "    (optimal_metrics_3['volatility']*100, optimal_metrics_3['cagr']*100, '3-Asset Optimal', '#627EEA', 200),\n",
    "    (optimal_metrics_5['volatility']*100, optimal_metrics_5['cagr']*100, '5-Asset Optimal', '#14F195', 200),\n",
    "]\n",
    "\n",
    "for vol, ret, name, color, size in portfolios:\n",
    "    ax.scatter(vol, ret, s=size, color=color, edgecolors='black', linewidths=2, zorder=5)\n",
    "    ax.annotate(name, (vol, ret), xytext=(10, 10), textcoords='offset points', \n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_title('Risk-Return Profile (Efficient Frontier)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Volatility (Annualized %)', fontsize=12)\n",
    "ax.set_ylabel('CAGR (%)', fontsize=12)\n",
    "\n",
    "cbar = plt.colorbar(ax.collections[0], ax=ax)\n",
    "cbar.set_label('Sharpe Ratio', fontsize=11)\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Bar Chart Comparison of Key Metrics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "metrics_to_plot = [\n",
    "    ('cagr', 'CAGR (%)', 100),\n",
    "    ('sharpe', 'Sharpe Ratio', 1),\n",
    "    ('sortino', 'Sortino Ratio', 1),\n",
    "    ('volatility', 'Volatility (%)', 100),\n",
    "    ('max_drawdown', 'Max Drawdown (%)', 100),\n",
    "    ('calmar', 'Calmar Ratio', 1)\n",
    "]\n",
    "\n",
    "portfolios_data = [\n",
    "    ('100% BTC', btc_metrics, '#F7931A'),\n",
    "    ('3-Asset', optimal_metrics_3, '#627EEA'),\n",
    "    ('5-Asset', optimal_metrics_5, '#14F195')\n",
    "]\n",
    "\n",
    "for idx, (metric_key, metric_name, multiplier) in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    values = [p[1][metric_key] * multiplier for p in portfolios_data]\n",
    "    colors = [p[2] for p in portfolios_data]\n",
    "    labels = [p[0] for p in portfolios_data]\n",
    "    \n",
    "    bars = ax.bar(labels, values, color=colors, edgecolor='black', linewidth=1)\n",
    "    ax.set_title(metric_name, fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{val:.2f}' if multiplier == 1 else f'{val:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.suptitle('Portfolio Metrics Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Allocation Pie Charts\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "colors_3 = ['#F7931A', '#627EEA', '#14F195']\n",
    "colors_5 = ['#F7931A', '#627EEA', '#14F195', '#F0B90B', '#23292F']\n",
    "\n",
    "# BTC Only\n",
    "axes[0].pie([100], labels=['BTC'], colors=['#F7931A'], autopct='%1.0f%%',\n",
    "            startangle=90, textprops={'fontsize': 12})\n",
    "axes[0].set_title('100% BTC', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3-Asset\n",
    "weights_3_pct = optimal_weights_3 * 100\n",
    "axes[1].pie(weights_3_pct, labels=assets_3, colors=colors_3, autopct='%1.0f%%',\n",
    "            startangle=90, textprops={'fontsize': 12})\n",
    "axes[1].set_title('3-Asset Optimal', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 5-Asset\n",
    "weights_5_pct = optimal_weights_5 * 100\n",
    "# Filter out 0% allocations for cleaner pie chart\n",
    "non_zero_idx = weights_5_pct > 0\n",
    "axes[2].pie(weights_5_pct[non_zero_idx], \n",
    "            labels=[a for a, nz in zip(assets_5, non_zero_idx) if nz], \n",
    "            colors=[c for c, nz in zip(colors_5, non_zero_idx) if nz], \n",
    "            autopct='%1.0f%%', startangle=90, textprops={'fontsize': 12})\n",
    "axes[2].set_title('5-Asset Optimal', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Optimal Portfolio Allocations', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 Rolling Sharpe Ratio (1-Year Window)\n",
    "def calculate_rolling_sharpe(portfolio_values, window=365):\n",
    "    daily_returns = portfolio_values.pct_change().dropna()\n",
    "    rolling_mean = daily_returns.rolling(window=window).mean() * 365\n",
    "    rolling_std = daily_returns.rolling(window=window).std() * np.sqrt(365)\n",
    "    rolling_sharpe = (rolling_mean - RISK_FREE_RATE) / rolling_std\n",
    "    return rolling_sharpe\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "rs_btc = calculate_rolling_sharpe(btc_values)\n",
    "rs_3 = calculate_rolling_sharpe(portfolio_3_values)\n",
    "rs_5 = calculate_rolling_sharpe(portfolio_5_values)\n",
    "\n",
    "ax.plot(rs_btc.index, rs_btc, label='100% BTC', linewidth=2, color='#F7931A')\n",
    "ax.plot(rs_3.index, rs_3, label='3-Asset', linewidth=2, color='#627EEA')\n",
    "ax.plot(rs_5.index, rs_5, label='5-Asset', linewidth=2, color='#14F195')\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axhline(y=1, color='green', linestyle='--', alpha=0.3, label='Sharpe = 1 (Good)')\n",
    "\n",
    "ax.set_title('Rolling 1-Year Sharpe Ratio', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Sharpe Ratio', fontsize=12)\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7 Correlation Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "corr_matrix = returns.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlGn_r', center=0, \n",
    "            fmt='.2f', square=True, linewidths=1, ax=ax,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "\n",
    "ax.set_title('Asset Correlation Matrix (Daily Returns)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monthly Performance Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly returns for each portfolio\n",
    "def get_monthly_returns(portfolio_values):\n",
    "    monthly = portfolio_values.resample('M').last()\n",
    "    monthly_returns = monthly.pct_change().dropna()\n",
    "    return monthly_returns\n",
    "\n",
    "# Create monthly returns dataframe\n",
    "monthly_btc = get_monthly_returns(btc_values)\n",
    "monthly_3 = get_monthly_returns(portfolio_3_values)\n",
    "monthly_5 = get_monthly_returns(portfolio_5_values)\n",
    "\n",
    "# Create heatmap data\n",
    "def create_monthly_heatmap_data(monthly_returns, name):\n",
    "    df = pd.DataFrame({'return': monthly_returns})\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    pivot = df.pivot(index='year', columns='month', values='return')\n",
    "    pivot.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'][:len(pivot.columns)]\n",
    "    return pivot\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "for ax, (monthly_data, title) in zip(axes, [\n",
    "    (monthly_btc, '100% BTC'),\n",
    "    (monthly_3, '3-Asset Optimal'),\n",
    "    (monthly_5, '5-Asset Optimal')\n",
    "]):\n",
    "    heatmap_data = create_monthly_heatmap_data(monthly_data, title)\n",
    "    sns.heatmap(heatmap_data * 100, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "                center=0, ax=ax, cbar_kws={'label': 'Return (%)'})\n",
    "    ax.set_title(f'Monthly Returns: {title}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Year')\n",
    "\n",
    "plt.suptitle('Monthly Performance Heatmaps', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS & CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Determine winners for each metric\n",
    "all_metrics = [\n",
    "    ('100% BTC', btc_metrics),\n",
    "    ('3-Asset', optimal_metrics_3),\n",
    "    ('5-Asset', optimal_metrics_5)\n",
    "]\n",
    "\n",
    "print(\"\\n1. SHARPE RATIO (Primary Metric - Risk-Adjusted Returns):\")\n",
    "sharpe_sorted = sorted(all_metrics, key=lambda x: x[1]['sharpe'], reverse=True)\n",
    "for i, (name, metrics) in enumerate(sharpe_sorted, 1):\n",
    "    emoji = ['[1st]', '[2nd]', '[3rd]'][i-1]\n",
    "    print(f\"   {emoji} {name}: {metrics['sharpe']:.3f}\")\n",
    "\n",
    "print(\"\\n2. TOTAL RETURN (Raw Performance):\")\n",
    "return_sorted = sorted(all_metrics, key=lambda x: x[1]['total_return'], reverse=True)\n",
    "for i, (name, metrics) in enumerate(return_sorted, 1):\n",
    "    emoji = ['[1st]', '[2nd]', '[3rd]'][i-1]\n",
    "    print(f\"   {emoji} {name}: {metrics['total_return']*100:.1f}%\")\n",
    "\n",
    "print(\"\\n3. MAX DRAWDOWN (Lowest is Best - Downside Protection):\")\n",
    "dd_sorted = sorted(all_metrics, key=lambda x: x[1]['max_drawdown'], reverse=True)  # Less negative is better\n",
    "for i, (name, metrics) in enumerate(dd_sorted, 1):\n",
    "    emoji = ['[1st]', '[2nd]', '[3rd]'][i-1]\n",
    "    print(f\"   {emoji} {name}: {metrics['max_drawdown']*100:.1f}%\")\n",
    "\n",
    "print(\"\\n4. SORTINO RATIO (Downside Risk-Adjusted Returns):\")\n",
    "sortino_sorted = sorted(all_metrics, key=lambda x: x[1]['sortino'], reverse=True)\n",
    "for i, (name, metrics) in enumerate(sortino_sorted, 1):\n",
    "    emoji = ['[1st]', '[2nd]', '[3rd]'][i-1]\n",
    "    print(f\"   {emoji} {name}: {metrics['sortino']:.3f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "best_sharpe_portfolio = sharpe_sorted[0][0]\n",
    "best_return_portfolio = return_sorted[0][0]\n",
    "\n",
    "print(f\"\\n- Best Risk-Adjusted Returns (Sharpe): {best_sharpe_portfolio}\")\n",
    "print(f\"- Best Raw Returns: {best_return_portfolio}\")\n",
    "\n",
    "# Compare to BTC\n",
    "sharpe_improvement_3 = ((optimal_metrics_3['sharpe'] / btc_metrics['sharpe']) - 1) * 100\n",
    "sharpe_improvement_5 = ((optimal_metrics_5['sharpe'] / btc_metrics['sharpe']) - 1) * 100\n",
    "\n",
    "print(f\"\\n- 3-Asset portfolio Sharpe improvement vs BTC: {sharpe_improvement_3:+.1f}%\")\n",
    "print(f\"- 5-Asset portfolio Sharpe improvement vs BTC: {sharpe_improvement_5:+.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Table for Export\n",
    "print(\"\\nFINAL SUMMARY TABLE (Copy-Paste Ready):\")\n",
    "print(\"\\n\" + comparison_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sensitivity Analysis: Impact of Rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test quarterly rebalancing vs no rebalancing\n",
    "def calculate_portfolio_value_with_rebalancing(weights, prices_df, initial_investment=INITIAL_INVESTMENT, rebalance_freq='Q'):\n",
    "    \"\"\"\n",
    "    Calculate portfolio value with periodic rebalancing.\n",
    "    rebalance_freq: 'Q' for quarterly, 'A' for annual, None for no rebalancing\n",
    "    \"\"\"\n",
    "    portfolio_values = []\n",
    "    current_value = initial_investment\n",
    "    \n",
    "    # Get rebalancing dates\n",
    "    if rebalance_freq:\n",
    "        rebalance_dates = prices_df.resample(rebalance_freq).last().index\n",
    "    else:\n",
    "        rebalance_dates = []\n",
    "    \n",
    "    # Initialize units\n",
    "    initial_prices = prices_df.iloc[0]\n",
    "    units = (initial_investment * np.array(weights)) / initial_prices\n",
    "    \n",
    "    for date in prices_df.index:\n",
    "        # Calculate current value\n",
    "        current_prices = prices_df.loc[date]\n",
    "        current_value = (units * current_prices).sum()\n",
    "        portfolio_values.append(current_value)\n",
    "        \n",
    "        # Rebalance if it's a rebalancing date\n",
    "        if rebalance_freq and date in rebalance_dates:\n",
    "            units = (current_value * np.array(weights)) / current_prices\n",
    "    \n",
    "    return pd.Series(portfolio_values, index=prices_df.index)\n",
    "\n",
    "# Compare with and without rebalancing\n",
    "print(\"Impact of Quarterly Rebalancing on 3-Asset Portfolio:\\n\")\n",
    "\n",
    "pv_3_no_rebal = calculate_portfolio_value(optimal_weights_3, prices[assets_3])\n",
    "pv_3_quarterly = calculate_portfolio_value_with_rebalancing(optimal_weights_3, prices[assets_3], rebalance_freq='Q')\n",
    "\n",
    "metrics_no_rebal = calculate_metrics(pv_3_no_rebal)\n",
    "metrics_quarterly = calculate_metrics(pv_3_quarterly)\n",
    "\n",
    "rebal_comparison = pd.DataFrame({\n",
    "    'Metric': ['CAGR', 'Sharpe Ratio', 'Max Drawdown', 'Final Value'],\n",
    "    'No Rebalancing': [\n",
    "        f\"{metrics_no_rebal['cagr']*100:.1f}%\",\n",
    "        f\"{metrics_no_rebal['sharpe']:.3f}\",\n",
    "        f\"{metrics_no_rebal['max_drawdown']*100:.1f}%\",\n",
    "        f\"${metrics_no_rebal['final_value']:,.0f}\"\n",
    "    ],\n",
    "    'Quarterly Rebalancing': [\n",
    "        f\"{metrics_quarterly['cagr']*100:.1f}%\",\n",
    "        f\"{metrics_quarterly['sharpe']:.3f}\",\n",
    "        f\"{metrics_quarterly['max_drawdown']*100:.1f}%\",\n",
    "        f\"${metrics_quarterly['final_value']:,.0f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(rebal_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV for further analysis or dashboard integration\n",
    "export_data = pd.DataFrame({\n",
    "    'date': prices.index,\n",
    "    'btc_only': btc_values.values,\n",
    "    'portfolio_3_asset': portfolio_3_values.values,\n",
    "    'portfolio_5_asset': portfolio_5_values.values\n",
    "})\n",
    "\n",
    "export_data.to_csv('portfolio_backtest_results.csv', index=False)\n",
    "print(\"Results exported to 'portfolio_backtest_results.csv'\")\n",
    "\n",
    "# Export optimal weights\n",
    "weights_export = {\n",
    "    'portfolio': ['3-Asset Optimal', '5-Asset Optimal'],\n",
    "    'BTC': [optimal_weights_3[0], optimal_weights_5[0]],\n",
    "    'ETH': [optimal_weights_3[1], optimal_weights_5[1]],\n",
    "    'SOL': [optimal_weights_3[2], optimal_weights_5[2]],\n",
    "    'BNB': [0, optimal_weights_5[3]],\n",
    "    'XRP': [0, optimal_weights_5[4]],\n",
    "    'Sharpe': [optimal_metrics_3['sharpe'], optimal_metrics_5['sharpe']],\n",
    "    'CAGR': [optimal_metrics_3['cagr'], optimal_metrics_5['cagr']]\n",
    "}\n",
    "pd.DataFrame(weights_export).to_csv('optimal_weights.csv', index=False)\n",
    "print(\"Optimal weights exported to 'optimal_weights.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "This analysis is for educational and informational purposes only. Past performance does not guarantee future results. Cryptocurrency investments carry significant risk and may result in substantial losses. The optimal allocations shown are based on historical data and may not be optimal going forward. Always conduct your own research and consider consulting a financial advisor before making investment decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
